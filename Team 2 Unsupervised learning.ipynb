{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Team 2 Unsupervised Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team 4 Unsupervised learning team members: \n",
    "Charles Maponya, \n",
    "Chuene Mokgokong,\n",
    "Kgomotso Moepe,\n",
    "Lesedi Madumo, \n",
    "Thabisile Obi, \n",
    "Tumelo Malebo\n",
    "\n",
    "[Trello board ](https://trello.com/b/dVQJqi5C/team4unsupervised)\n",
    "\n",
    "## Problem Statement \n",
    "Accurately predict unseen movie ratings gathered from thousands of users based on their historic preferences. \n",
    "\n",
    "The objective of this notebook is to construct a recommendation algorithm based on content and collaborative filtering, capable of accurately predicting how a user will rate a movie they have not watched yet based on their historical preference.   \n",
    "\n",
    "![image.png](https://manofmany.com/wp-content/uploads/2020/04/Veboli-new-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Comet experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment with your api key:\n",
    "experiment = Experiment(\n",
    "    api_key=,\n",
    "    project_name=,\n",
    "    workspace=,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043027,
     "end_time": "2020-12-08T11:04:47.360247",
     "exception": false,
     "start_time": "2020-12-08T11:04:47.31722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Table of contents:\n",
    "\n",
    "### [1. Introduction](#introduction)\n",
    "\n",
    "### [2. Import libaries and datasets](#libaries)\n",
    "\n",
    "### [3. Exploratory Data Analysis](#eda)\n",
    "\n",
    "* [Summary statistics](#sub1)\n",
    "* [Visualizing the dataframes](#sub2)\n",
    "* [Visualizing the null values for each dataframe](#sub3)\n",
    "* [Visualizing common users](#sub4)\n",
    "* [Exploring movie genres](#sub5) \n",
    "* [Exploring the movies dataframe](#sub6)\n",
    "* [Word cloud](#sub7)\n",
    "* [Publishing years](#sub8)\n",
    "* [Budget](#sub9)\n",
    "\n",
    "### [4. Prepocessing](#prep)\n",
    "\n",
    "\n",
    "### [5. Modelling](#mod)\n",
    "\n",
    "* [Content-Based Filtering Recommendation](#CB)\n",
    "* [Collaborative-Based Filtering Reccomendation](#CB1)\n",
    "\n",
    "### [6. Evaluation](#eva)\n",
    "\n",
    "### [7. Conclusion](#conc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046421,
     "end_time": "2020-12-08T11:04:47.449955",
     "exception": false,
     "start_time": "2020-12-08T11:04:47.403534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [1. Introduction](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are systems that are designed to recommend things to the user based on many different factors. These systems predict the most likely product that the user is most likely to purchase and are of interest. Companies like Netflix and Amazon use recommender systems to help their users to identify the correct product or movies for them.\n",
    "\n",
    "Recommender systems are an important class of machine learning algorithms that offer relevant suggestions to users. The suggested items are as relevant to the user as possible so that the user can engage with those items: YouTube videos, news articles, online products, movie and series recommendation.\n",
    "\n",
    "Items are ranked according to their relevancy, and the most relevant ones are shown to the user. The relevance is determined by the recommender system, mainly based on historical data. For example, If you've recently watched YouTube videos about elephants, then YouTube is going to start showing you many elephant videos with similar titles and themes. \n",
    "Recommender systems are generally divided into two main categories: collaborative filtering and content-based systems.\n",
    "\n",
    "![image.png](https://miro.medium.com/max/690/1*G4h4fOX6bCJhdmbsXDL0PA.png)\n",
    " \n",
    "Both users and service providers have benefited from these kinds of systems. Intelligent algorithms can help viewers find great titles from tens of thousands of options. This notebook will construct a recommendation algorithm based on content and collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historic preferences.\n",
    "\n",
    "Providing an accurate and robust solution will have immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2. Import libaries and datasets](#libaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:04:44.284424Z",
     "iopub.status.busy": "2020-12-08T11:04:44.28346Z",
     "iopub.status.idle": "2020-12-08T11:04:47.273048Z",
     "shell.execute_reply": "2020-12-08T11:04:47.272348Z"
    },
    "papermill": {
     "duration": 3.051155,
     "end_time": "2020-12-08T11:04:47.273188",
     "exception": false,
     "start_time": "2020-12-08T11:04:44.222033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "        \n",
    "import surprise\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "import time\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "import re\n",
    "import plotly.express as px\n",
    "import scipy as sp\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline  import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, Normalizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all Necessary Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:04:47.654675Z",
     "iopub.status.busy": "2020-12-08T11:04:47.653887Z",
     "iopub.status.idle": "2020-12-08T11:05:10.204791Z",
     "shell.execute_reply": "2020-12-08T11:05:10.203972Z"
    },
    "papermill": {
     "duration": 22.607814,
     "end_time": "2020-12-08T11:05:10.20494",
     "exception": false,
     "start_time": "2020-12-08T11:04:47.597126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = '/kaggle/input/edsa-recommender-system-predict/'\n",
    "#data_folder = 'C:/Users/ADMIN/Desktop/unsupervised_project/'\n",
    "train_df = pd.read_csv(data_folder + 'train.csv')\n",
    "test_df = pd.read_csv(data_folder + 'test.csv')\n",
    "tags_df = pd.read_csv(data_folder + 'tags.csv')\n",
    "movies_df = pd.read_csv(data_folder + 'movies.csv')\n",
    "links_df = pd.read_csv(data_folder + 'links.csv')\n",
    "imdb_df = pd.read_csv(data_folder + 'imdb_data.csv')\n",
    "genome_tags = pd.read_csv(data_folder + 'genome_tags.csv')\n",
    "genome_score = pd.read_csv(data_folder + 'genome_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044141,
     "end_time": "2020-12-08T11:05:10.382871",
     "exception": false,
     "start_time": "2020-12-08T11:05:10.33873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [3. Exploratory Data Analysis](#eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. EDA is the critical process of performing initial investigations on data to discover patterns, to spot anomalies, to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n",
    "\n",
    "A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modelling or hypothesis testing task.\n",
    "\n",
    "It is a good practice to understand the data first and try to gather as many insights from it. EDA is all about making sense of data in hand, before getting them dirty with it, which will be done below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Summary statistics](#sub1)\n",
    "Pandas dataframe.info() function is used to get a concise summary of the dataframe. It comes really handy when doing exploratory analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a summary stats function\n",
    "def Summary(df):\n",
    "    return df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(links_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(imdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(genome_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(genome_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the DataFrames have a Dtype of int64 and float64, which is an indication for numeric values. However, some DataFrames also have Dtype of an object, which is an indication of non-numeric character. The DataFrames which have a Dtype include tags_df; movies_df; imdb_df; and genome_df. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting The shapes of our data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train data:',train_df.shape) \n",
    "print('test data:',test_df.shape)\n",
    "print('tags data:',tags_df.shape)\n",
    "print(\"Movies data:\",movies_df.shape)\n",
    "print('links data:',links_df.shape)\n",
    "print('imdb data:',imdb_df.shape)\n",
    "print('genome tags data:',genome_tags.shape)\n",
    "print('genome scores data:',genome_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046907,
     "end_time": "2020-12-08T11:05:12.858703",
     "exception": false,
     "start_time": "2020-12-08T11:05:12.811796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Visualizing the dataframes](#sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:12.971972Z",
     "iopub.status.busy": "2020-12-08T11:05:12.971096Z",
     "iopub.status.idle": "2020-12-08T11:05:12.976522Z",
     "shell.execute_reply": "2020-12-08T11:05:12.975788Z"
    },
    "papermill": {
     "duration": 0.069418,
     "end_time": "2020-12-08T11:05:12.976647",
     "exception": false,
     "start_time": "2020-12-08T11:05:12.907229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Created a Data Frame outlining the size of our data\n",
    "dataframes = ['train_df', 'test_df', 'tags_df', 'imdb_df',\n",
    "              'links_df', 'movies_df', 'genome_tags', 'genome_score']\n",
    "sizes = [len(train_df), len(test_df), len(tags_df),\n",
    "         len(imdb_df), len(links_df), len(movies_df),\n",
    "         len(genome_tags), len(genome_score)]\n",
    "total_size_df = pd.DataFrame(list(zip(dataframes, sizes)),\n",
    "                             columns=['dataframe', 'sizes'])\n",
    "total_size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:13.208227Z",
     "iopub.status.busy": "2020-12-08T11:05:13.207425Z",
     "iopub.status.idle": "2020-12-08T11:05:13.210987Z",
     "shell.execute_reply": "2020-12-08T11:05:13.21158Z"
    },
    "papermill": {
     "duration": 0.068066,
     "end_time": "2020-12-08T11:05:13.211735",
     "exception": false,
     "start_time": "2020-12-08T11:05:13.143669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_size_df = total_size_df[total_size_df['sizes'] > 100000]\n",
    "total_size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:13.091047Z",
     "iopub.status.busy": "2020-12-08T11:05:13.089904Z",
     "iopub.status.idle": "2020-12-08T11:05:13.094868Z",
     "shell.execute_reply": "2020-12-08T11:05:13.094133Z"
    },
    "papermill": {
     "duration": 0.068261,
     "end_time": "2020-12-08T11:05:13.094992",
     "exception": false,
     "start_time": "2020-12-08T11:05:13.026731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_row = {'dataframe': 'other', 'sizes': 180530}\n",
    "total_size_df = total_size_df.append(new_row,\n",
    "                                     ignore_index=True)\n",
    "total_size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:13.319351Z",
     "iopub.status.busy": "2020-12-08T11:05:13.318597Z",
     "iopub.status.idle": "2020-12-08T11:05:13.603873Z",
     "shell.execute_reply": "2020-12-08T11:05:13.6031Z"
    },
    "papermill": {
     "duration": 0.342838,
     "end_time": "2020-12-08T11:05:13.604008",
     "exception": false,
     "start_time": "2020-12-08T11:05:13.26117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "explodeTuple = (0.05, 0.04, 0.05, 0.04, 0.6)\n",
    "fig1, ax1 = plt.subplots(figsize=(14,7))\n",
    "ax1.pie(total_size_df['sizes'].values,\n",
    "        labels=total_size_df['dataframe'].values,\n",
    "        startangle=90, autopct='%1.1f%%',\n",
    "        explode=explodeTuple)\n",
    "ax1.axis('equal')\n",
    "plt.title('Distribution of overall Data Frames')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:13.7709Z",
     "iopub.status.busy": "2020-12-08T11:05:13.765629Z",
     "iopub.status.idle": "2020-12-08T11:05:13.808566Z",
     "shell.execute_reply": "2020-12-08T11:05:13.807772Z"
    },
    "papermill": {
     "duration": 0.153799,
     "end_time": "2020-12-08T11:05:13.808694",
     "exception": false,
     "start_time": "2020-12-08T11:05:13.654895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_list = [['train_df', len(train_df)], ['tags_df', len(tags_df)],\n",
    "            ['imdb_df', len(imdb_df)], ['links_df', len(links_df)],\n",
    "            ['movies_df', len(movies_df)],\n",
    "            ['genome_tags', len(genome_tags)],\n",
    "            ['genome_score', len(genome_score)]]\n",
    "len_df = pd.DataFrame(len_list,\n",
    "                      columns=['Dataset', 'Size'])\n",
    "fig = px.bar(len_df, x=len_df['Dataset'],\n",
    "             y=len_df['Size'],\n",
    "             color=len_df['Dataset'],\n",
    "             title='Distribution of overall Data Frames')\n",
    "fig.update_layout(legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.02,\n",
    "    xanchor=\"right\",\n",
    "    x=1\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame's that are visualised in the pie chart are the DataFrames with a size larger than 100000. The DataFrames that had a larger size than 100000 include the train_df; test_df; tags_df; genome_score and other. While the DataFrame's that had a size smaller than 100000 were combined into a DataFrame 'other', these DataFrames are imdb_df; links_df, movies_df; and genome_tags. \n",
    "\n",
    "In the pie chart, it is visually seen that the genome_score DataFrame size (48.9%) accounts for almost 50% of the DataFrame sizes. Followed by train_df account for 31.4%. The DataFrame with the least size is the other, with an attribute of only 0.6%.\n",
    "\n",
    "In the bar graph, the precise unequal distribution of DataFrame sizes is evident. The genome_score DataFrame has the largest size, followed by the train_df. The difference in distribution sizes is clear, where the other DataFrame's bars aren't visually evident because of the large difference between the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052169,
     "end_time": "2020-12-08T11:05:13.912556",
     "exception": false,
     "start_time": "2020-12-08T11:05:13.860387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Visualizing the null values for each dataframe](#sub3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:14.028439Z",
     "iopub.status.busy": "2020-12-08T11:05:14.027064Z",
     "iopub.status.idle": "2020-12-08T11:05:14.396877Z",
     "shell.execute_reply": "2020-12-08T11:05:14.396157Z"
    },
    "papermill": {
     "duration": 0.432974,
     "end_time": "2020-12-08T11:05:14.397006",
     "exception": false,
     "start_time": "2020-12-08T11:05:13.964032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtaining the total null values in each Data Frames columns\n",
    "train_count = pd.DataFrame(train_df.isnull().sum())\n",
    "test_count = pd.DataFrame(test_df.isnull().sum())\n",
    "tags_count = pd.DataFrame(tags_df.isnull().sum())\n",
    "movies_count = pd.DataFrame(movies_df.isnull().sum())\n",
    "links_count = pd.DataFrame(links_df.isnull().sum())\n",
    "imdb_count = pd.DataFrame(imdb_df.isnull().sum())\n",
    "genomet_count = pd.DataFrame(genome_tags.isnull().sum())\n",
    "genomes_count = pd.DataFrame(genome_score.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:14.509282Z",
     "iopub.status.busy": "2020-12-08T11:05:14.508174Z",
     "iopub.status.idle": "2020-12-08T11:05:14.512913Z",
     "shell.execute_reply": "2020-12-08T11:05:14.512277Z"
    },
    "papermill": {
     "duration": 0.064328,
     "end_time": "2020-12-08T11:05:14.513039",
     "exception": false,
     "start_time": "2020-12-08T11:05:14.448711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:14.625846Z",
     "iopub.status.busy": "2020-12-08T11:05:14.624962Z",
     "iopub.status.idle": "2020-12-08T11:05:14.629946Z",
     "shell.execute_reply": "2020-12-08T11:05:14.629302Z"
    },
    "papermill": {
     "duration": 0.064728,
     "end_time": "2020-12-08T11:05:14.630073",
     "exception": false,
     "start_time": "2020-12-08T11:05:14.565345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:14.752793Z",
     "iopub.status.busy": "2020-12-08T11:05:14.751666Z",
     "iopub.status.idle": "2020-12-08T11:05:15.053576Z",
     "shell.execute_reply": "2020-12-08T11:05:15.052814Z"
    },
    "papermill": {
     "duration": 0.370783,
     "end_time": "2020-12-08T11:05:15.053698",
     "exception": false,
     "start_time": "2020-12-08T11:05:14.682915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.bar(tags_count.index,\n",
    "        tags_count.values.reshape(len(tags_count), ),\n",
    "        color='red')\n",
    "plt.xlabel('column_name')\n",
    "plt.ylabel('count')\n",
    "plt.title('Null value count in tags_df')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:15.171988Z",
     "iopub.status.busy": "2020-12-08T11:05:15.171109Z",
     "iopub.status.idle": "2020-12-08T11:05:15.175371Z",
     "shell.execute_reply": "2020-12-08T11:05:15.174655Z"
    },
    "papermill": {
     "duration": 0.066943,
     "end_time": "2020-12-08T11:05:15.175522",
     "exception": false,
     "start_time": "2020-12-08T11:05:15.108579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:15.296041Z",
     "iopub.status.busy": "2020-12-08T11:05:15.294909Z",
     "iopub.status.idle": "2020-12-08T11:05:15.299616Z",
     "shell.execute_reply": "2020-12-08T11:05:15.299006Z"
    },
    "papermill": {
     "duration": 0.06837,
     "end_time": "2020-12-08T11:05:15.299736",
     "exception": false,
     "start_time": "2020-12-08T11:05:15.231366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "links_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:15.427616Z",
     "iopub.status.busy": "2020-12-08T11:05:15.426034Z",
     "iopub.status.idle": "2020-12-08T11:05:15.595858Z",
     "shell.execute_reply": "2020-12-08T11:05:15.595055Z"
    },
    "papermill": {
     "duration": 0.240176,
     "end_time": "2020-12-08T11:05:15.595989",
     "exception": false,
     "start_time": "2020-12-08T11:05:15.355813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.bar(imdb_count.index,\n",
    "        imdb_count.values.reshape(len(imdb_count), ),\n",
    "        color='orange')\n",
    "plt.xlabel('column_name')\n",
    "plt.ylabel('count')\n",
    "plt.title('Null value count in imdb_df')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is essential to check whether your dataset has missing values. The real-world data often has a lot of missing values. The cause of missing values can be data corruption or failure to record data. The handling of missing data is critical during the preprocessing of the dataset, as many machine learning algorithms do not support missing values.\n",
    "\n",
    "The DataFrame's with null values include the tags_df and imdb_df.\n",
    "In the tags_df, the column with null values is the tag column as seen by the red bar in the Null value count in tags_df bar graph. \n",
    "In the imdb_df, there are five columns with null values, with the budget column having the most null values of over 17500. \n",
    "There are several methods for dealing with missing values. This includes:\n",
    "\n",
    "1. Deleting Rows with missing values\n",
    "2. Impute missing values for continuous variable\n",
    "3. Impute missing values for categorical variable\n",
    "4. Other Imputation Methods\n",
    "5. Using Algorithms that support missing values\n",
    "6. Prediction of missing values\n",
    "7. Imputation using Deep Learning Library — Datawig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045633,
     "end_time": "2020-12-08T11:05:11.208651",
     "exception": false,
     "start_time": "2020-12-08T11:05:11.163018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Visualizing common users](#sub4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:10.599103Z",
     "iopub.status.busy": "2020-12-08T11:05:10.59827Z",
     "iopub.status.idle": "2020-12-08T11:05:11.116623Z",
     "shell.execute_reply": "2020-12-08T11:05:11.115741Z"
    },
    "papermill": {
     "duration": 0.576709,
     "end_time": "2020-12-08T11:05:11.116755",
     "exception": false,
     "start_time": "2020-12-08T11:05:10.540046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To find the number of times a user rated a movie, we create a data frame with the count by userId\n",
    "train_user = pd.DataFrame(\n",
    "    train_df['userId'].value_counts()).reset_index()\n",
    "train_user.rename(columns={'index':'userId','userId':'count'},\n",
    "                  inplace=True)\n",
    "train_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:11.312323Z",
     "iopub.status.busy": "2020-12-08T11:05:11.31143Z",
     "iopub.status.idle": "2020-12-08T11:05:11.375077Z",
     "shell.execute_reply": "2020-12-08T11:05:11.374376Z"
    },
    "papermill": {
     "duration": 0.120212,
     "end_time": "2020-12-08T11:05:11.375213",
     "exception": false,
     "start_time": "2020-12-08T11:05:11.255001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grouping the users within a certain range aided us in determining the common userId's and the new ones.\n",
    "group_one = train_user.loc[(train_user['count'] > 0) & \n",
    "            (train_user['count'] < 50),\n",
    "            'userId'].value_counts().sum()\n",
    "group_two = train_user.loc[(train_user['count'] >= 50) & \n",
    "            (train_user['count'] < 500),\n",
    "            'userId'].value_counts().sum()\n",
    "group_three = train_user.loc[(train_user['count'] >= 500) & \n",
    "            (train_user['count'] < 1000),\n",
    "            'userId'].value_counts().sum()\n",
    "group_four = train_user.loc[(train_user['count'] >= 1000) & \n",
    "            (train_user['count'] < 1500),\n",
    "            'userId'].value_counts().sum()\n",
    "group_five = train_user.loc[(train_user['count'] >= 1500),\n",
    "            'userId'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:11.477946Z",
     "iopub.status.busy": "2020-12-08T11:05:11.477055Z",
     "iopub.status.idle": "2020-12-08T11:05:12.763306Z",
     "shell.execute_reply": "2020-12-08T11:05:12.763954Z"
    },
    "papermill": {
     "duration": 1.343505,
     "end_time": "2020-12-08T11:05:12.764131",
     "exception": false,
     "start_time": "2020-12-08T11:05:11.420626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To give us insight in the spread, we used figures to determine the spread.\n",
    "trial_error = np.array([['group_one', group_one,\n",
    "                         'between 1 and 50'],\n",
    "                        ['group_two', group_two,\n",
    "                         'between 50 and 500'],\n",
    "                        ['group_three', group_three,\n",
    "                         'between 500 and 1000'],\n",
    "                        ['group_four', group_four,\n",
    "                         'between 1000 and 1500'],\n",
    "                        ['group_five', group_five,\n",
    "                         'greater than 1500']])\n",
    "trial_error_df = pd.DataFrame({'group': trial_error[:, 0],\n",
    "                               'userId_grouping': trial_error[:, 1],\n",
    "                               'explanation': trial_error[:, 2]})\n",
    "fig = px.bar(trial_error_df,\n",
    "             x=trial_error_df[\"group\"],\n",
    "             y=trial_error_df[\"userId_grouping\"],\n",
    "             color=trial_error_df[\"group\"],\n",
    "             title='Grouped Rating Distribustion')\n",
    "fig.update_layout(legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.02,\n",
    "    xanchor=\"right\",\n",
    "    x=1\n",
    "))\n",
    "fig.show()\n",
    "trial_error_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user Id's are grouped by the rating counts in a grouping range illustrated in the DataFrame above.  In the Grouped Rating Distribution bar graph, it is visually displayed that there is unequal distribution.  The distribution is skewed to the left, with the majority of the user ids in the rating count range between 1 and 50. At the same time, the last group has only a value count of 61, which is a significant difference from group one with a value count of 110 010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_ratings_count(df, n):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    data = df['userId'].value_counts().head(n)\n",
    "    ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n",
    "    plt.title(f'Top {n} Users by Number of Ratings', fontsize=14)\n",
    "    plt.xlabel('User ID')\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_count(train_df,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b color='darkslateblue'>Filtering out user 72315 because his/her number of raings is too extreme and he/she is an oulier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_count(train_df[train_df['userId'] !=72315],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are certain things which, if they are not done in the EDA phase, can affect further statistical / Machine Learning modelling. One of the things is to find outliers. Once user 72315 was removed from the top 10 users by the number of ratings, a more uniform pattern of voting is evident in the bar graph. \n",
    "\n",
    "In statistics, an outlier is an observation point that is distant from other observations. The definition suggests to us that an outlier is something which is an odd-one-out or the one that is different from the crowd. Some statisticians define outliers as 'having a different underlying behaviour than the rest of the data'.  Alternatively, an outlier is a data point that is distant from other points.\n",
    "The Top 10 User by Number of Ratings graph that includes user 72315 is not a representation of an imbalanced dataset. An imbalanced data set in terms of machine learning is where one class label has far fewer samples compared to another class label. In this case, user 72315 deviates significantly from the rest of the users. \n",
    "\n",
    "![image.png](https://datascience.foundation/img/pdf_images/knowing_all_about_outliers_in_machine_learning_sample_points_in_green_are_near_to_each_other.jpg)\n",
    "\n",
    "From the image above we can see that the sample points in Green are close to each other, whereas the two sample points in Red are far apart from them. These red sample points are outliers.\n",
    "Machine learning algorithms are sensitive to the range and distribution of attribute values. Data outliers can spoil and mislead the training process resulting in longer  training times, less accurate models and ultimately more inferior results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058331,
     "end_time": "2020-12-08T11:05:15.969374",
     "exception": false,
     "start_time": "2020-12-08T11:05:15.911043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Exploring Movie Genres](#sub5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:16.101129Z",
     "iopub.status.busy": "2020-12-08T11:05:16.100372Z",
     "iopub.status.idle": "2020-12-08T11:05:16.287751Z",
     "shell.execute_reply": "2020-12-08T11:05:16.287109Z"
    },
    "papermill": {
     "duration": 0.260112,
     "end_time": "2020-12-08T11:05:16.287884",
     "exception": false,
     "start_time": "2020-12-08T11:05:16.027772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "genres = pd.DataFrame(movies_df['genres'].\n",
    "                      str.split(\"|\").\n",
    "                      tolist(),\n",
    "                      index=movies_df['movieId']).stack()\n",
    "genres = genres.reset_index([0, 'movieId'])\n",
    "genres.columns = ['movieId', 'Genre']\n",
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:16.553843Z",
     "iopub.status.busy": "2020-12-08T11:05:16.548187Z",
     "iopub.status.idle": "2020-12-08T11:05:17.043566Z",
     "shell.execute_reply": "2020-12-08T11:05:17.042805Z"
    },
    "papermill": {
     "duration": 0.564373,
     "end_time": "2020-12-08T11:05:17.043689",
     "exception": false,
     "start_time": "2020-12-08T11:05:16.479316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "sns.countplot(x='Genre',\n",
    "              data=genres,\n",
    "              palette='CMRmap',\n",
    "              order=genres['Genre'].\n",
    "              value_counts().index)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Genre', size=20)\n",
    "plt.ylabel('Count', size=20)\n",
    "plt.title('Distribution of Movie Genres', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 most popular movie genres include drama, comedy and thriller. \n",
    "A Genre consists of four elements or parts: character, story, plot and setting. And often people will state that a particular movie had a good plot or an intriguing story. What people are referring to is that they enjoyed the characters, the problems/conflict the characters got into, and how the characters got out of the problems and conflict. The drama genre could be the most popular because it caters the character development in the plot, often overcoming dome form of challenge and conflicts, i.e. human struggles.  According to Hayley Mckenzie, drama delivers the emotional and relational development of realistic characters in a realistic setting. It offers intense character development and tells an honest story of human struggle. And this could be the possible reason why drama is a popular genre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exploring the Movies data](#sub6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.merge(train_df, movies_df,on='movieId',how='inner')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_movies = pd.merge(movies,imdb_df,on='movieId',how='inner')\n",
    "full_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_plot_by_ratings(df,column, n):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    data = df[str(column)].value_counts().head(n)\n",
    "    ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n",
    "    plt.title(f'Top {n} {column.title()} by Number of Ratings', fontsize=14)\n",
    "    plt.xlabel(column.title())\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_plot_by_ratings(movies,'title',15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Top 15 Title by Number of Ratings bar graph, all the movies are prior the year 2001, with 14 of them released in the 19th century. \n",
    "\n",
    "The top three are Shawshank Redemption 1994, Forest Grump 1994 and Pulp Fiction 1994.  All three movies fall under the popular drama genre and are American.\n",
    "The Shawshank Redemption is a 1994 American drama film written and directed by Frank Darabont, based on the 1982 Stephen King novella Rita Hayworth and Shawshank Redemption. \n",
    "Pulp Fiction is a 1994 American neo-noir black comedy crime film written and directed by Quentin Tarantino, who conceived it with Roger Avary.\n",
    "Forrest Gump is a 1994 American romantic comedy-drama film directed by Robert Zemeckis and written by Eric Roth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of movie titles\n",
    "movies_word = movies_df['title'] = movies_df['title'].astype('str')\n",
    "movies_wordcloud = ' '.join(movies_word)\n",
    "title_wordcloud = WordCloud(stopwords = STOPWORDS,\n",
    "                            background_color = 'White',\n",
    "                            height = 1200,\n",
    "                            width = 900).generate(movies_wordcloud)\n",
    "plt.figure(figsize = (14,7), facecolor=None)\n",
    "plt.imshow(title_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Distribution of words from movie titles')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_plot_by_ratings(movies,'rating',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common rating score that is give is 4.0, followed by 3.0. The least common score that is given by usrs is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_plot_by_ratings(full_movies,'director',15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quentin Tarantino is the top director of the number of ratings. Quentin Tarantino is one of the world's most renowned writer/directors. Each of his films is highly anticipated, as he draws upon the subjects and themes of previous films to produce a fresh storyline. Three of the most significant works from Quentin Tarantino are Reservoir Dogs, True Romance and Pulp Fiction. \n",
    "\n",
    "\n",
    "![image.png](https://img.theculturetrip.com/1440x/smart/images/56-3992968-1001514452-58f5b96a08.jpg)\n",
    "\n",
    "And as seen in the by the Top 15 Title by Number of Ratings graph, Pulp Fiction is one of the top 3 most voted films. \n",
    "For best director he was nominated for: \n",
    "\n",
    "1994\tPulp Fiction\tNominated\n",
    "\n",
    "2009\tInglourious Basterds\tNominated\n",
    "\n",
    "2019\tOnce Upon a Time in Hollywood\tNominated\n",
    "\n",
    "Other competing directors include Michael Crichton and J.R.R. Tolkien. However, Quentin Tarantino does have a more considerable leading as compared to other directors in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRatingDistGroup = train_df['rating'].value_counts().sort_index().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.barplot(data=movieRatingDistGroup, x='index', y='rating', palette=\"CMRmap\", edgecolor=\"black\", ax=ax)\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel('Number of Users')\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "total = float(movieRatingDistGroup['rating'].sum())\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2., height+350, '{0:.2%}'.format(height/total), fontsize=11, ha=\"center\", va='bottom')\n",
    "plt.title('Number of Users Per Rating', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the users are weighted within the score range of 3.0 - 5.0, with the most users being weighted in the 4.0 score, accounting for 26.53% of the users. This indicates that most of the users give ratings above 2.5, and with fewer users giving a score of 0.5 which only only consists of 1.58% of the users. Similiarly with the score of 1.5 only accounting to 1.60% of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_directors(df, count = 10):\n",
    "    \"\"\"\n",
    "    Function to count the most common dircetors in a DataFrame:\n",
    "    Parameters\n",
    "    ----------\n",
    "        df (DataFrame): input dataframe containing imdb metadata\n",
    "        count (int): filter directors with fewer than count films\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        directors (DataFrame): output DataFrame\n",
    "    Examples\n",
    "    --------\n",
    "        >>> df = pd.DataFrame({'imdbid':[0,1,2,3,4,5], 'director': [A,B,A,C,B]})\n",
    "        >>> count_directors(df, count = 1)\n",
    "            |index|director|count|\n",
    "            |0|A|2|\n",
    "            |1|B|2|\n",
    "            |2|C|1|\n",
    "    \"\"\"\n",
    "    directors = pd.DataFrame(df['director'].value_counts()).reset_index()\n",
    "    directors.columns = ['director', 'count']\n",
    "    # Lets only take directors who have made 10 or more movies otherwise we will have to analyze 11000 directors\n",
    "    directors = directors[directors['count']>=count]\n",
    "    return directors.sort_values('count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_count(df, column):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    ax = sns.barplot(x = df[f'{column}'], y= df['count'], palette='brg')\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n",
    "    plt.title(f'Number of Movies Per {column}', fontsize=14)\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors = count_directors(imdb_df)\n",
    "feature_count(directors.head(15), 'director')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count(directors[directors['director']!='See full summary'].head(15), 'director')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Number of Movies Per Director bar graph, the leading director who has produced the most movies is 'See full summary' with a count of 28. However, 'see the full summary' is not a director! \n",
    "Luc Besson and Woody Allen are tied with a value count of producing 26 movies and followed by Stephan King with 24.  They are the only producers in the dataset with over 20 movie productions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059818,
     "end_time": "2020-12-08T11:05:17.163716",
     "exception": false,
     "start_time": "2020-12-08T11:05:17.103898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Word Clouds](#sub7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:17.312243Z",
     "iopub.status.busy": "2020-12-08T11:05:17.307318Z",
     "iopub.status.idle": "2020-12-08T11:05:36.56016Z",
     "shell.execute_reply": "2020-12-08T11:05:36.560948Z"
    },
    "papermill": {
     "duration": 19.33617,
     "end_time": "2020-12-08T11:05:36.56114",
     "exception": false,
     "start_time": "2020-12-08T11:05:17.22497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comment_words = ''\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# iterate through the csv file\n",
    "for val in tags_df['tag']:\n",
    "\n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    "\n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "\n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "\n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    "  \n",
    "wordcloud = WordCloud(width=1200, height=900,\n",
    "                      colormap='winter',\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,collocations=False,\n",
    "                      min_font_size=10).generate(comment_words)\n",
    "\n",
    "# plot the WordCloud image\n",
    "plt.figure(figsize=(14, 7), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Distribution of words in the tags data frame by Tags')\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:36.948563Z",
     "iopub.status.busy": "2020-12-08T11:05:36.947769Z",
     "iopub.status.idle": "2020-12-08T11:05:37.10738Z",
     "shell.execute_reply": "2020-12-08T11:05:37.106634Z"
    },
    "papermill": {
     "duration": 0.476581,
     "end_time": "2020-12-08T11:05:37.107523",
     "exception": false,
     "start_time": "2020-12-08T11:05:36.630942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_count = pd.DataFrame(tags_df['tag'].\n",
    "                           value_counts()).reset_index()\n",
    "value_count.rename(columns = {'index': 'genre', 'tag': 'count'},\n",
    "                   inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:37.255938Z",
     "iopub.status.busy": "2020-12-08T11:05:37.254957Z",
     "iopub.status.idle": "2020-12-08T11:05:37.260034Z",
     "shell.execute_reply": "2020-12-08T11:05:37.25939Z"
    },
    "papermill": {
     "duration": 0.084245,
     "end_time": "2020-12-08T11:05:37.260153",
     "exception": false,
     "start_time": "2020-12-08T11:05:37.175908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count = value_count.head(20)\n",
    "plt.figure(figsize=(14,7))\n",
    "ax = sns.barplot(x = genre_count['genre'], y= genre_count['count'], palette='CMRmap')\n",
    "for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n",
    "plt.title('Number of times a genre tag appears', fontsize=14)\n",
    "plt.xlabel('Genre tag')\n",
    "plt.ylabel('Genre tag Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular words in the world cloud include book, comedy, ending, based, dark and sci-fi.  \n",
    "The three most popular genres that appear in tags_df('tags') are sci-fi, atmospheric, and action. The sci-fi genre is a speculative fiction that typically deals with imaginative and futuristic concepts such as advanced science and technology, space exploration, time travel, parallel universes, and extraterrestrial life.  While atmospheric films tap in the sentimental human memory may be portals to another time and space.  For instance, scenes that give an opportunity of temporal teleportation for the nostalgic visionary. The action genre has the protagonist or protagonists who thrust into a series of events that typically include violence, extended fighting, physical feats, rescues and frantic chases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068468,
     "end_time": "2020-12-08T11:05:37.397501",
     "exception": false,
     "start_time": "2020-12-08T11:05:37.329033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Publishing Years](#sub8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:37.552547Z",
     "iopub.status.busy": "2020-12-08T11:05:37.547169Z",
     "iopub.status.idle": "2020-12-08T11:05:37.647981Z",
     "shell.execute_reply": "2020-12-08T11:05:37.648572Z"
    },
    "papermill": {
     "duration": 0.180455,
     "end_time": "2020-12-08T11:05:37.648752",
     "exception": false,
     "start_time": "2020-12-08T11:05:37.468297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "for title in movies_df['title']:\n",
    "    if title[-1] == \" \":\n",
    "        year = title[-6: -2]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "    else:\n",
    "        year = title[-5: -1]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "\n",
    "movies_df['Publish Year'] = dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:37.805826Z",
     "iopub.status.busy": "2020-12-08T11:05:37.80063Z",
     "iopub.status.idle": "2020-12-08T11:05:37.90006Z",
     "shell.execute_reply": "2020-12-08T11:05:37.89943Z"
    },
    "papermill": {
     "duration": 0.180167,
     "end_time": "2020-12-08T11:05:37.900197",
     "exception": false,
     "start_time": "2020-12-08T11:05:37.72003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "for title in movies_df['title']:\n",
    "    if title[-1] == \" \":\n",
    "        year = title[-6: -2]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "    else:\n",
    "        year = title[-5: -1]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "\n",
    "movies_df['Publish Year'] = dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:38.050716Z",
     "iopub.status.busy": "2020-12-08T11:05:38.049581Z",
     "iopub.status.idle": "2020-12-08T11:05:38.054196Z",
     "shell.execute_reply": "2020-12-08T11:05:38.053428Z"
    },
    "papermill": {
     "duration": 0.083631,
     "end_time": "2020-12-08T11:05:38.054328",
     "exception": false,
     "start_time": "2020-12-08T11:05:37.970697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:38.203322Z",
     "iopub.status.busy": "2020-12-08T11:05:38.202545Z",
     "iopub.status.idle": "2020-12-08T11:05:38.214673Z",
     "shell.execute_reply": "2020-12-08T11:05:38.215378Z"
    },
    "papermill": {
     "duration": 0.09039,
     "end_time": "2020-12-08T11:05:38.215554",
     "exception": false,
     "start_time": "2020-12-08T11:05:38.125164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(movies_df[movies_df['Publish Year'] == 9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:38.366741Z",
     "iopub.status.busy": "2020-12-08T11:05:38.36594Z",
     "iopub.status.idle": "2020-12-08T11:05:38.386674Z",
     "shell.execute_reply": "2020-12-08T11:05:38.38739Z"
    },
    "papermill": {
     "duration": 0.098086,
     "end_time": "2020-12-08T11:05:38.387564",
     "exception": false,
     "start_time": "2020-12-08T11:05:38.289478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df[(movies_df['Publish Year'] > 1888) &\n",
    "          (movies_df['Publish Year'] < 2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:38.53934Z",
     "iopub.status.busy": "2020-12-08T11:05:38.538591Z",
     "iopub.status.idle": "2020-12-08T11:05:38.557323Z",
     "shell.execute_reply": "2020-12-08T11:05:38.556584Z"
    },
    "papermill": {
     "duration": 0.097441,
     "end_time": "2020-12-08T11:05:38.557458",
     "exception": false,
     "start_time": "2020-12-08T11:05:38.460017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(movies_df['Publish Year'].\n",
    "                       value_counts()).reset_index()\n",
    "dataset.rename(columns={'index': 'year', 'Publish Year': 'count'},\n",
    "               inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:38.716679Z",
     "iopub.status.busy": "2020-12-08T11:05:38.715843Z",
     "iopub.status.idle": "2020-12-08T11:05:38.799777Z",
     "shell.execute_reply": "2020-12-08T11:05:38.800333Z"
    },
    "papermill": {
     "duration": 0.168417,
     "end_time": "2020-12-08T11:05:38.800516",
     "exception": false,
     "start_time": "2020-12-08T11:05:38.632099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_dataset = dataset[(dataset['year']>1888) & (dataset['year']<2021)].sort_values(by='count',ascending=False).head(50)\n",
    "plt.figure(figsize=(14,7))\n",
    "ax = sns.barplot(x = year_dataset['year'], y= year_dataset['count'], order=year_dataset['year'], palette='CMRmap')\n",
    "#for p in ax.patches:\n",
    "#       ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n",
    "plt.title('Number of Movies Released Per year', fontsize=14)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Released Movie Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Number of  Movies Released Per year graph, we are able to visually see an major increase in movie releases in the 21st century. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Budget](#sub9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_l = list(imdb_df['budget'])\n",
    "print(type(new_l[9]))\n",
    "\n",
    "imdb_df['runtime'] = imdb_df['runtime'].fillna(imdb_df['runtime'].mean())\n",
    "imdb_df.isnull().sum() #data cleaning\n",
    "imdb_df.head()\n",
    "imdb_df['budget'] = imdb_df['budget'].str.replace('[\\,]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(text):\n",
    "    text = re.sub(r'[0-9]+', \"\", str(text))\n",
    "    return text\n",
    "imdb_df['currency'] = imdb_df['budget'].apply(clean_txt)\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies = list(imdb_df['currency'])\n",
    "# Number of currencies\n",
    "len(set(currencies))-1\n",
    "\n",
    "currencies_count_df = pd.DataFrame(imdb_df['currency'].\n",
    "                                   value_counts()).reset_index()\n",
    "currencies_count_df.rename(columns={'index': 'currency', 'currency': 'count'},\n",
    "                           inplace=True)\n",
    "currencies_count_df.head()\n",
    "\n",
    "fig = px.bar(currencies_count_df, x=currencies_count_df['currency'],\n",
    "             y=currencies_count_df['count'],\n",
    "             color=currencies_count_df['currency'],\n",
    "             title='Currency Type Distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4. Prepocessing](#prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Dimensional Scaling \n",
    "\n",
    "Multidimensional scaling (MDS) is a technique for visualizing distances between objects on a map, where the distance is known between pairs of the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaler(df):\n",
    "    \"\"\"\n",
    "    Scales data.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler(with_std=True)\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome= genome_score[:10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_genome = data_scaler(genome.sample(frac=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(3, n_jobs = -1, verbose = 2, perplexity = 10, learning_rate = 0.1)\n",
    "tsne.fit(scaled_genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Add 3D scatter plot\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(tsne.embedding_[:,0], tsne.embedding_[:,1], tsne.embedding_[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(x = tsne.embedding_[:,0], y = tsne.embedding_[:,1], size=tsne.embedding_[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:39.214605Z",
     "iopub.status.busy": "2020-12-08T11:05:39.213807Z",
     "iopub.status.idle": "2020-12-08T11:05:39.217871Z",
     "shell.execute_reply": "2020-12-08T11:05:39.217208Z"
    },
    "papermill": {
     "duration": 0.193028,
     "end_time": "2020-12-08T11:05:39.217994",
     "exception": false,
     "start_time": "2020-12-08T11:05:39.024966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Below is the dataframe we will be altering.\n",
    "working_train = train_df.drop(columns='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:39.375297Z",
     "iopub.status.busy": "2020-12-08T11:05:39.374441Z",
     "iopub.status.idle": "2020-12-08T11:05:44.006498Z",
     "shell.execute_reply": "2020-12-08T11:05:44.005644Z"
    },
    "papermill": {
     "duration": 4.714098,
     "end_time": "2020-12-08T11:05:44.006641",
     "exception": false,
     "start_time": "2020-12-08T11:05:39.292543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_work = working_train.set_index('movieId').join([movies_df[['movieId',\n",
    "                                                           'genres']]\n",
    "                                                   .set_index('movieId'),\n",
    "                                                   imdb_df[['movieId',\n",
    "                                                         'title_cast',\n",
    "                                                         'director',\n",
    "                                                         'plot_keywords']].\n",
    "                                                   set_index('movieId')],\n",
    "                                                  how='left').reset_index()\n",
    "df_work.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:44.225218Z",
     "iopub.status.busy": "2020-12-08T11:05:44.224128Z",
     "iopub.status.idle": "2020-12-08T11:05:44.227048Z",
     "shell.execute_reply": "2020-12-08T11:05:44.227626Z"
    },
    "papermill": {
     "duration": 0.093113,
     "end_time": "2020-12-08T11:05:44.227789",
     "exception": false,
     "start_time": "2020-12-08T11:05:44.134676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_train(df):\n",
    "    working_train = df.copy()\n",
    "\n",
    "    # Merge\n",
    "    df_work = working_train.set_index('movieId').join([movies_df\n",
    "                                                       [['movieId', 'genres']].\n",
    "                                                       set_index('movieId'),\n",
    "                                                       imdb_df[['movieId',\n",
    "                                                             'title_cast',\n",
    "                                                             'director',\n",
    "                                                             'plot_keywords']].\n",
    "                                                       set_index('movieId')],\n",
    "                                                      how='left').reset_index()\n",
    "\n",
    "# '(no genre listed)' is an equivalent of a missing value in the column genres\n",
    "\n",
    "    df_work['genres'] = ['' if x == '(no genres listed)' else x for x in df_work['genres']]\n",
    "\n",
    "    # filling missing values with 'nothing'... (emptying...?)\n",
    "    df_work.fillna('', inplace=True)\n",
    "\n",
    "    for col in df_work.select_dtypes('object').columns: # selecting 'object' columns\n",
    "\n",
    "        # removing white space\n",
    "        df_work[col] = [''.join(x.split()) for x in df_work[col]]\n",
    "\n",
    "        # substituting '|' with a white space\n",
    "        df_work[col] = [' '.join(x.split('|')) for x in df_work[col]]\n",
    "\n",
    "    # joining the features of interest\n",
    "    df_work['corpus'] =  df_work[df_work.select_dtypes('object').columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "    return df_work[['movieId', 'userId', 'corpus', 'rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:44.39188Z",
     "iopub.status.busy": "2020-12-08T11:05:44.386667Z",
     "iopub.status.idle": "2020-12-08T11:05:44.395772Z",
     "shell.execute_reply": "2020-12-08T11:05:44.394944Z"
    },
    "papermill": {
     "duration": 0.093092,
     "end_time": "2020-12-08T11:05:44.3959",
     "exception": false,
     "start_time": "2020-12-08T11:05:44.302808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_test(df):\n",
    "    working_train = df.copy()\n",
    "\n",
    "    # Merge\n",
    "    df_work = working_train.set_index('movieId').join([movies_df\n",
    "                                                       [['movieId', 'genres']].\n",
    "                                                       set_index('movieId'),\n",
    "                                                       imdb_df[['movieId',\n",
    "                                                             'title_cast',\n",
    "                                                             'director',\n",
    "                                                             'plot_keywords']].\n",
    "                                                       set_index('movieId')],\n",
    "                                                      how='left').reset_index()\n",
    "\n",
    "# '(no genre listed)' is an equivalent of a missing value in the column genres\n",
    "\n",
    "    df_work['genres'] = ['' if x == '(no genres listed)' else x for x in df_work['genres']]\n",
    "\n",
    "    # filling missing values with 'nothing'... (emptying...?)\n",
    "    df_work.fillna('', inplace=True)\n",
    "\n",
    "    for col in df_work.select_dtypes('object').columns: # selecting 'object' columns\n",
    "\n",
    "        # removing white space\n",
    "        df_work[col] = [''.join(x.split()) for x in df_work[col]]\n",
    "\n",
    "        # substituting '|' with a white space\n",
    "        df_work[col] = [' '.join(x.split('|')) for x in df_work[col]]\n",
    "\n",
    "    # joining the features of interest\n",
    "    df_work['corpus'] =  df_work[df_work.select_dtypes('object').columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "    return df_work[['movieId', 'userId', 'corpus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:05:44.554116Z",
     "iopub.status.busy": "2020-12-08T11:05:44.553267Z",
     "iopub.status.idle": "2020-12-08T11:07:39.756158Z",
     "shell.execute_reply": "2020-12-08T11:07:39.755371Z"
    },
    "papermill": {
     "duration": 115.284432,
     "end_time": "2020-12-08T11:07:39.756302",
     "exception": false,
     "start_time": "2020-12-08T11:05:44.47187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Test = preprocessor_test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:07:40.024561Z",
     "iopub.status.busy": "2020-12-08T11:07:40.022859Z",
     "iopub.status.idle": "2020-12-08T11:11:29.134102Z",
     "shell.execute_reply": "2020-12-08T11:11:29.133257Z"
    },
    "papermill": {
     "duration": 229.300754,
     "end_time": "2020-12-08T11:11:29.134287",
     "exception": false,
     "start_time": "2020-12-08T11:07:39.833533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = preprocessor_train(train_df.drop(columns=['timestamp'])) # DO NOT RUN THIS ON LOCAL COMPUTER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:11:29.614709Z",
     "iopub.status.busy": "2020-12-08T11:11:29.612462Z",
     "iopub.status.idle": "2020-12-08T11:11:29.759806Z",
     "shell.execute_reply": "2020-12-08T11:11:29.759037Z"
    },
    "papermill": {
     "duration": 0.549387,
     "end_time": "2020-12-08T11:11:29.759928",
     "exception": false,
     "start_time": "2020-12-08T11:11:29.210541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1 = X.drop(columns=['rating', 'userId', 'movieId'])\n",
    "T1 = Test.drop(columns=['userId', 'movieId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:11:29.918371Z",
     "iopub.status.busy": "2020-12-08T11:11:29.917392Z",
     "iopub.status.idle": "2020-12-08T11:11:29.920857Z",
     "shell.execute_reply": "2020-12-08T11:11:29.920056Z"
    },
    "papermill": {
     "duration": 0.085307,
     "end_time": "2020-12-08T11:11:29.920993",
     "exception": false,
     "start_time": "2020-12-08T11:11:29.835686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = X['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:11:30.10289Z",
     "iopub.status.busy": "2020-12-08T11:11:30.092379Z",
     "iopub.status.idle": "2020-12-08T11:16:36.025042Z",
     "shell.execute_reply": "2020-12-08T11:16:36.025728Z"
    },
    "papermill": {
     "duration": 306.026787,
     "end_time": "2020-12-08T11:16:36.025936",
     "exception": false,
     "start_time": "2020-12-08T11:11:29.999149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_mat =cv.fit_transform(X1['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:16:36.246473Z",
     "iopub.status.busy": "2020-12-08T11:16:36.22046Z",
     "iopub.status.idle": "2020-12-08T11:19:02.518854Z",
     "shell.execute_reply": "2020-12-08T11:19:02.518149Z"
    },
    "papermill": {
     "duration": 146.414023,
     "end_time": "2020-12-08T11:19:02.518987",
     "exception": false,
     "start_time": "2020-12-08T11:16:36.104964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Test_mat = cv.transform(T1['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:19:02.677244Z",
     "iopub.status.busy": "2020-12-08T11:19:02.676271Z",
     "iopub.status.idle": "2020-12-08T11:19:02.680805Z",
     "shell.execute_reply": "2020-12-08T11:19:02.680207Z"
    },
    "papermill": {
     "duration": 0.085326,
     "end_time": "2020-12-08T11:19:02.68092",
     "exception": false,
     "start_time": "2020-12-08T11:19:02.595594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.075457,
     "end_time": "2020-12-08T11:05:38.95059",
     "exception": false,
     "start_time": "2020-12-08T11:05:38.875133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [5. Modelling](#mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.077369,
     "end_time": "2020-12-08T11:19:02.835641",
     "exception": false,
     "start_time": "2020-12-08T11:19:02.758272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [Content-Based Filtering Recommendation](#CB)\n",
    "\n",
    "Collaborative filtering addresses some of the limitations of content-based filtering; collaborative filtering uses similarities between users and items simultaneously to provide recommendations. This allows for serendipitous recommendations; that is, collaborative filtering models can recommend an item to user A based on the interests of a similar user B. Furthermore, the embeddings can be learned automatically, without relying on hand-engineering of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Model\n",
    "Simple linear regression is a statistical method that shows the relationship between two continuous variables. This is represented by a straight line with the equation:\n",
    "$$ y = a + bx$$   \n",
    "where $a$ is the intercept of the line with the y-axis, and $b$ is the gradient.  \n",
    "The independent variable ($x$) is also known as the predictor and the dependent variable ($y$) is known as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T11:19:02.999586Z",
     "iopub.status.busy": "2020-12-08T11:19:02.998547Z",
     "iopub.status.idle": "2020-12-08T11:51:42.174557Z",
     "shell.execute_reply": "2020-12-08T11:51:42.1752Z"
    },
    "papermill": {
     "duration": 1959.262374,
     "end_time": "2020-12-08T11:51:42.175373",
     "exception": false,
     "start_time": "2020-12-08T11:19:02.912999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators2 = []\n",
    "estimators2.append(('standardize',\n",
    "                    StandardScaler(with_mean=False)))\n",
    "estimators2.append(('mod',\n",
    "                    LinearRegression()))\n",
    "model = Pipeline(estimators2)\n",
    "model.fit(X_mat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merged each movie with its genre, casts, director and plot keywords.\n",
    "\n",
    "We wanted to find out how similar the test movies are to any movie the user has rated before, then rate the 'test movie' by the highest similarity in any rating category.\n",
    "\n",
    "Therefore, for each user, we categorised the movies viewers have watched by rating.\n",
    "\n",
    "Results for the linear regression model predicted a RMSE of 1.06. We can conclude therefore that there are not enough variables to lower the RMSE though this still proved to be the best performing model for content based filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "# Break up the big genre string into a string array\n",
    "genre = movies_df['genres'].str.split('|')\n",
    "genre = movies_df['genres'].fillna(\"\").astype('str')\n",
    "sample_genre = genre.head(20000)   # remove sample on EC2 to acess the whole dataset\n",
    "#create a Tf_idf vectorizer\n",
    "tf = TfidfVectorizer(analyzer = 'word',\n",
    "                     ngram_range = (1, 3),\n",
    "                     min_df = 0,\n",
    "                     stop_words = 'english')\n",
    "vecto = tf.fit_transform(sample_genre)     # replace sample_genre with genre\n",
    "# cosine similarities\n",
    "cosine_sim = linear_kernel(vecto, vecto)\n",
    "# The movie_recommendation function\n",
    "def movie_recommendations(movie):\n",
    "    # set the movie title as the new index\n",
    "    movie_index=pd.Series(movies_df.index,\n",
    "                          index = movies_df['title'])\n",
    "    # generate  similarities between the movie title and movie index based on genre\n",
    "    similarities = list(enumerate(cosine_sim[movie_index[movie]]))\n",
    "    similarities = sorted(similarities, key = lambda x: x[1],\n",
    "                          reverse = True)[1:11]\n",
    "    movie_recommendation = movies_df['title'].iloc[[i[0] for i in similarities]]\n",
    "    return movie_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_recommendations('Into the West (2005)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Content-Based Recommendation system computes similarity between movies based on movie genres using the selected movie as a baseline. The TF-IDF vectorizer was used to find the relationship in terms of relative importance of the movie.\n",
    "The systems make use of Cosine Similarity to compute numeric quantities that highlights the similarities between the movies (one as a baseline).\n",
    "A function was assembled to estimate top 10 movies that are similar to the base movie using genre as a basis.\n",
    "The function was passed an input (‘Into the West (2005)’), a baseline and generated top 10 similar movies using cosine similarity score computed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Collaborative-Based Filtering Reccomendation](#CB1)\n",
    "Collaborative filtering addresses some of the limitations of content-based filtering; collaborative filtering uses similarities between users and items simultaneously to provide recommendations. This allows for serendipitous recommendations; that is, collaborative filtering models can recommend an item to user A based on the interests of a similar user B. Furthermore, the embeddings can be learned automatically, without relying on hand-engineering of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 1M dataset\n",
    "train_df.drop('timestamp', axis=1)\n",
    "train_subset = train_df[:1000000]\n",
    "reader = Reader(rating_scale=(train_subset['rating'].min(), train_subset['rating'].max()))\n",
    "data = Dataset.load_from_df(train_subset[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix Factorization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-negative matrix factorization, also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into two matrices W and H, with the property that all three matrices have no negative elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_epochs=50, n_factors=200, random_state=42,verbose=True)\n",
    "nmf_model.fit(trainset)\n",
    "nmf_predictions =nmf_model.test(testset)\n",
    "nmf_rmse = accuracy.rmse(nmf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SlopeOne Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slope One is a family of algorithms used for collaborative filtering, introduced in a 2005 paper by Daniel Lemire and Anna Maclachlan. Arguably, it is the simplest form of non-trivial item-based collaborative filtering based on ratings. Their simplicity makes it especially easy to implement them efficiently while their accuracy is often on par with more complicated and computationally expensive algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slo_model = SlopeOne()\n",
    "slo_model.fit(trainset)\n",
    "slo_predictions = slo_model.test(testset)\n",
    "slo_rmse=accuracy.rmse(slo_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CoClustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biclustering, block clustering , co-clustering, or two-mode clustering is a data mining technique which allows simultaneous clustering of the rows and columns of a matrix. The term was first introduced by Boris Mirkin to name a technique introduced many years earlier, in 1972, by J. A. Hartigan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_model = CoClustering(n_epochs=50,random_state=42)\n",
    "cc_model.fit(trainset)\n",
    "cc_predictions = cc_model.test(testset)\n",
    "cc_rmse=accuracy.rmse(cc_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The singular value decomposition (SVD) provides another way to factorize a matrix, into singular vectors and singular values. The SVD allows us to discover some of the same kind of information as the eigendecomposition.The SVD is used widely both in the calculation of other matrix operations, such as matrix inverse, but also as a data reduction method in machine learning. SVD can also be used in least squares linear regression, image compression, and denoising data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = SVD(n_epochs=50,n_factors=400,init_std_dev=0.001,random_state=42,verbose=True)\n",
    "svd_model.fit(trainset)\n",
    "svd_predictions = svd_model.test(testset)\n",
    "svd_rmse = accuracy.rmse(svd_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition plus-plus (SVDpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD++ algorithm, an extension of SVD taking into account implicit ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdpp_model = SVDpp(n_epochs=50,n_factors=400,init_std_dev=0.001,random_state=42, verbose=True)\n",
    "svdpp_model.fit(trainset)\n",
    "svdpp_predictions = svdpp_model.test(testset)\n",
    "svdpp_rmse = accuracy.rmse(svdpp_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BaselineOnly algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm predicting the baseline estimate for given user and item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl_options = {'method': 'sgd','n_epochs': 50}\n",
    "blo_model = BaselineOnly(bsl_options=bsl_options,verbose=True)\n",
    "blo_model.fit(trainset)\n",
    "blo_predictions = blo_model.test(testset)\n",
    "# Calculate RMSE\n",
    "blo_rmse = accuracy.rmse(blo_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [6. Evaluation](#eva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built and tested six different collaborative filtering models and compared their performance using a statistical measure known as the root mean squared error (**RMSE**), which determines the average squared difference between the estimated values and the actual value. A low RMSE value indicates high model accuracy.\n",
    "\n",
    "### Root Mean Squared Error (RMSE):\n",
    "$$RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{d_i -f_i}{\\sigma_i}\\Big)^2}}$$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores =[nmf_rmse,slo_rmse,cc_rmse,svd_rmse,svdpp_rmse,blo_rmse]\n",
    "models =['NMF','SlopeOne','CoClustering','SVD','SVD++','BaselineOnly']\n",
    "\n",
    "accuracy_data = pd.DataFrame({'model':models,'RMSE':rmse_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data.sort_values(by='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.barplot(data=accuracy_data.sort_values(by='RMSE'), x='model', y='RMSE', palette=\"CMRmap\", edgecolor=\"black\", ax=ax)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel('RMSE Score')\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width()/2, p.get_y() + p.get_height(), round(p.get_height(),3), fontsize=12, ha=\"center\", va='bottom')\n",
    "plt.title('Model Accuracy By RMSE Score', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Explainability and Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of machine learning and artificial intelligence, <b>explainability</b> and <b>interpretability</b> are often used interchangeably. While they are very closely related, it’s worth unpicking the differences, if only to see how complicated things can get once you start digging deeper into machine learning systems.\n",
    "\n",
    "<b>Interpretability</b> is about the extent to which a cause and effect can be observed within a system. Or, to put it another way, it is the extent to which you are able to predict what is going to happen, given a change in input or algorithmic parameters. It’s being able to look at an algorithm and go yep, I can see what’s happening here.\n",
    "\n",
    "<b>Explainability</b>, meanwhile, is the extent to which the internal mechanics of a machine or deep learning system can be explained in human terms. \n",
    "\n",
    "It’s easy to miss the subtle difference with interpretability, but consider it like this: interpretability is about being able to discern the mechanics without necessarily knowing why. Explainability is being able to quite literally explain what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [7. Conclusion](#con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook, YouTube, LinkedIn are among the most used websites on the internet today that use recommender systems. Facebook suggests us to make more friends using the 'People You May Know' section. Similarly, LinkedIn recommends you connect with people you may know, and YouTube suggests relevant videos based on your previous browsing history. All of these are recommender systems in action.\n",
    "\n",
    "While most of the people are aware of these features, only a few know that the algorithms used behind these features are known as 'Recommender Systems'. They 'recommend' personalised content based on user's past / current preference to improve the user experience. \n",
    "\n",
    "We were tasked with accurately predicting unseen movie ratings gathered from thousands of users based on their historic preferences. \n",
    "\n",
    "Broadly, there are two types of recommendation systems: Content-Based and Collaborative filtering based as mention. In the notebook, we observation algorithms of both content-based and collaborative filtering. \n",
    "\n",
    "When we used the linear regression model (content-based) on the test data, it produced an RMSE score of 0.82565. However, the Singular Value Decomposition (collaborative-filtering) performed better on the test data with an <b>RMSE score of 0.80773<b> , which is our final score on the Kaggle leaderboard. \n",
    "\n",
    "Our [streamlit app](http://54.74.35.46:500) has interactive unsupervised learning models that can assist your business to have better customer usage by recommending items that of interest to each user. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
